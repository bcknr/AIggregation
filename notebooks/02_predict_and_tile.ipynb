{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02: Model prediction and tiling for validation\n",
    "Authors: Tobias G. Mueller, Mark A. Buckner\n",
    "Last modified: 4 Dec 2024\n",
    "Contact: __________\n",
    "\n",
    "**Summary**: Here, we predict on an orthomosaic using our pretrained model. \n",
    "We then split the predictions and image into smaller tiles and take a random 40% for ground truthing and model validation.\n",
    "\n",
    "\n",
    "This script outputs \n",
    "- predicted nest detections in yolov5 format \n",
    "- a random 20% of tiles into a testset folder \n",
    "\n",
    "The data used in this script was generated in:\n",
    "    `AIggregation/notebooks/01_preprocessing.ipynb`\n",
    "\n",
    "This script is followed by `03_validation_and_optimization.ipynb`. However the test tiles created in this script will need to be annotated before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import os\n",
    "import fiftyone as fo\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "from PIL import Image \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first check the wd is not notebooks but the main folder\n",
    "print(\"cwd is\", os.getcwd())\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "    print(\"cwd changed to\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect nests on orthomosaic using sahi\n",
    "\n",
    "Using our trained nest detection model we predict on our stitched orthomosaic image using SAHI (slicing aided hyper-inference)   -- `https://github.com/obss/sahi`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "# -------------------------------------------------------------------------------------------------------------------- #\n",
    "image_directory = \"datasets/drone_ortho/ortho_clip_23april.png\"     # path to image to be predicted on\n",
    "model_path = \"AIggregation_yolov5m/weights/best.pt\"                      # path to image detection model\n",
    "predictions_directory = \"datasets/export_predictions/temp\"                    # directory to export model predictions to\n",
    "# --------------------------------------------------------------------- ----------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "# Import ortho image into a fiftyone dataset \n",
    "dataset_full = fo.Dataset.from_images(\n",
    "    [image_directory]\n",
    ")\n",
    "\n",
    "# specify AI detection model to use for predictions\n",
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type='yolov5',\n",
    "    model_path=model_path, #specify path to trained model\n",
    "    confidence_threshold=0.25,\n",
    "    device=device, # \"cpu\" or \"cuda:0\" for GPU (if available)\n",
    ")\n",
    "\n",
    "# define function for sliced predictions from sahi\n",
    "def predict_with_slicing(sample, label_field, **kwargs):\n",
    "    result = get_sliced_prediction(\n",
    "        sample.filepath, detection_model, verbose=0, **kwargs\n",
    "    )\n",
    "    sample[label_field] = fo.Detections(detections=result.to_fiftyone_detections())\n",
    "\n",
    "# predict on image, slicing at training image size\n",
    "for sample in dataset_full.iter_samples(progress=True, autosave=True):\n",
    "    predict_with_slicing(sample,\n",
    "                         label_field=\"prediction\",\n",
    "                         slice_height=608, \n",
    "                         slice_width=608,\n",
    "                         overlap_height_ratio = .4, \n",
    "                         overlap_width_ratio=.4\n",
    "    )\n",
    "\n",
    "\n",
    "#launch fiftyone session to see predictions\n",
    "session = fo.launch_app(dataset_full)\n",
    "\n",
    "\n",
    "#export predictions\n",
    "dataset_full.export(\n",
    "        export_dir=predictions_directory,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        label_field=\"prediction\",\n",
    "        include_confidence=True\n",
    "    )\n",
    "\n",
    "# Importing image, predicting, and export took\n",
    "# 7m 53s using CPU (AMD Ryzen 5 5500 3.6 GHz 6-Core Processor)\n",
    "# 2m 38s using GPU (EVGA SC GAMING GeForce GTX 1060 3GB 3 GB Video Card)\n",
    "# 64 gb DDR4-3200 ram\n",
    "\n",
    "# for half resolution dataset it took 38.1 seconds using GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a test set for validation\n",
    "\n",
    "To assess the model performance we will compare the predictions vs a labeled random subset.\n",
    "\n",
    "To do this, we split the predicted upon image and its detections into many smaller tiles, then randomly select 40% of them to act as our test set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set parameters for tiling script\n",
    "# -------------------------------------------------------------------------------------------------------------------- #\n",
    "source_path = predictions_directory                    # directory where model prediction exported to\n",
    "target_path = \"./datasets/testset/tiled_testset\"       # directory to save tiled testset\n",
    "img_ext = \".png\"                                       # type of image predicted on\n",
    "tile_size = 608                                        # size of tiles in pixels. default 608\n",
    "all_images = \"TRUE\"                                    # set to FALSE to only keep images with detections\n",
    "test_ratio = 0.4                                       # proportion of tiles to keep for testset\n",
    "overwrite = \"TRUE\"                                     # set to TRUE to create new testlist. Default to pulling from existing list in one folder up from target\n",
    "# -------------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# set max image pixels to none\n",
    "# otherwise pillow thinks large images might be a bomb DOS attack \n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "\n",
    "# run riling script using above parameters\n",
    "%run scripts/yolo_tile_modified.py -source {source_path} -target {target_path} -ext {img_ext}  -size {tile_size} -ratio {test_ratio} -overwrite {overwrite} -all_images {all_images}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate test set \n",
    "\n",
    "Before continuing to `03_validation_and_optimization.ipynb` the tiled testset must be annotated with ground truth labels.\n",
    "\n",
    "Import the tiled images in the testset folder into labelstudio and annotate them. These will be used in the next notebook to validate the model predictions and optimize the detections. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
